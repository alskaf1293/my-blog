<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Timothy Oh</title>
<link>https://alskaf1293.github.io/my-blog/</link>
<atom:link href="https://alskaf1293.github.io/my-blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Wed, 14 Jan 2026 00:00:00 GMT</lastBuildDate>
<item>
  <title>Non Degenerate First Order Perturbation Theory</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post7/</link>
  <description><![CDATA[ 





<p>Perturbation theory is the study of solving problems that are almost solvable, where the system that you’re trying to solve for is close to one that can be solved exactly.</p>
<p>First, we start with nondegenerate perturbation theory, where</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH_%7B0%7D%20%5Cket%7Bn%5E%7B(0)%7D%7D%20=%20E%5E%7B(0)%7D_n%20%5Cket%7Bn%5E%7B(0)%7D%7D%0A"></p>
<p>where the nondegeneracy condition requires that</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE%5E%7B(0)%7D_n%20%5Cneq%20E%5E%7B(0)%7D_m%0A"></p>
<p>for all <img src="https://latex.codecogs.com/png.latex?n%20%5Cneq%20m">. We start from the time independent Schrodinger equation in operator form</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH%5Cket%7Bn%7D=E_n%20%5Cket%7Bn%7D%0A"></p>
<p>where our Hamiltonian is expanded in terms of the perturbation parameterized by <img src="https://latex.codecogs.com/png.latex?%5Clambda"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH=H_0+%5Clambda%20V%0A"></p>
<p>It’s important to note here that V is not the potential, but the pertubation that we are adding to see how our energies and solutions are affected. \</p>
<p>The idea then is to expand the energies and solution kets in a power series</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE_n=E%5E%7B(0)%7D_n+%5Clambda%20E%5E%7B(1)%7D_n+%5Clambda%5E2%20E%5E%7B(2)%7D_n%20+%20%5Cdots%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cket%7Bn%7D=%5Cket%7Bn%5E%7B(0)%7D%7D+%5Clambda%20%5Cket%7Bn%5E%7B(1)%7D%7D+%5Clambda%5E2%20%5Cket%7Bn%5E%7B(2)%7D%7D%20+%20%5Cdots%0A"></p>
<p>Plugging these relations back into the time independent Schrodinger Equation</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(H_0+%5Clambda%20V)(%5Cket%7Bn%5E%7B(0)%7D%7D+%5Clambda%20%5Cket%7Bn%5E%7B(1)%7D%7D+%5Clambda%5E2%20%5Cket%7Bn%5E%7B(2)%7D%7D%20+%20%5Cdots)%0A=(E%5E%7B(0)%7D_n+%5Clambda%20E%5E%7B(1)%7D_n+%5Clambda%5E2%20E%5E%7B(2)%7D_n%20+%20%5Cdots)(%5Cket%7Bn%5E%7B(0)%7D%7D+%5Clambda%20%5Cket%7Bn%5E%7B(1)%7D%7D+%5Clambda%5E2%20%5Cket%7Bn%5E%7B(2)%7D%7D%20+%20%5Cdots)%0A"></p>
<p>If you expand this out, well the terms would be infinite. However, we can group this expansion in terms of their order in <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p><strong>First order non degenerate perturbation theory</strong></p>
<p>For first order perturbation theory, we only consider the terms above that are linear in <img src="https://latex.codecogs.com/png.latex?%5Clambda">. Expanding it out, we have that in order 0 in <img src="https://latex.codecogs.com/png.latex?%5Clambda">, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH_0%5Cket%7Bn%5E%7B(0)%7D%7D=E%5E%7B(0)%7D_n%5Cket%7Bn%5E%7B(0)%7D%7D%0A"></p>
<p>which we have taken to already be true. For order 1 in <img src="https://latex.codecogs.com/png.latex?%5Clambda">, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AV%5Cket%7Bn%5E%7B(0)%7D%7D+H_0%5Cket%7Bn%5E%7B(1)%7D%7D=E%5E%7B(0)%7D_n%5Cket%7Bn%5E%7B(1)%7D%7D+E%5E%7B(1)%7D_n%5Cket%7Bn%5E%7B(0)%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(V-E%5E%7B(1)%7D_n)%5Cket%7Bn%5E%7B(0)%7D%7D=(E%5E%7B(0)%7D_n-H_0)%5Cket%7Bn%5E%7B(1)%7D%7D%0A"></p>
<p>Taking the inner product, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7Bn%5E%7B(0)%7D%7D(V-E%5E%7B(1)%7D_n)%5Cket%7Bn%5E%7B(0)%7D%7D=%5Cbra%7Bn%5E%7B(0)%7D%7D(E%5E%7B(0)%7D_n-H_0)%5Cket%7Bn%5E%7B(1)%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7Bn%5E%7B(0)%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D-E%5E%7B(1)%7D_n=0%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cboxed%7BE%5E%7B(1)%7D_n=%5Cbra%7Bn%5E%7B(0)%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D%7D%0A"></p>
<p>The first order energy correction. To find the expression for the first order solution correction <img src="https://latex.codecogs.com/png.latex?%5Cket%7Bn%5E%7B(1)%7D%7D"> we start from the order 1 expression again</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AV%5Cket%7Bn%5E%7B(0)%7D%7D+H_0%5Cket%7Bn%5E%7B(1)%7D%7D=E%5E%7B(0)%7D_n%5Cket%7Bn%5E%7B(1)%7D%7D+E%5E%7B(1)%7D_n%5Cket%7Bn%5E%7B(0)%7D%7D%0A"></p>
<p>Multiply both sides by <img src="https://latex.codecogs.com/png.latex?%5Cbra%7Bm%5E%7B0%7D%7D"> where <img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7Bm%5E%7B0%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D+%5Cbra%7Bm%5E%7B0%7D%7DH_0%5Cket%7Bn%5E%7B(1)%7D%7D=%5Cbra%7Bm%5E%7B0%7D%7DE%5E%7B(0)%7D_n%5Cket%7Bn%5E%7B(1)%7D%7D+%5Cbra%7Bm%5E%7B0%7D%7DE%5E%7B(1)%7D_n%5Cket%7Bn%5E%7B(0)%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7Bm%5E%7B0%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D+E%5E%7B(0)%7D_m%5Cbraket%7Bm%5E%7B0%7D%7Cn%5E%7B(1)%7D%7D=E%5E%7B(0)%7D_n%5Cbraket%7Bm%5E%7B0%7D%7Cn%5E%7B(1)%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7Bm%5E%7B0%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D=(E%5E%7B(0)%7D_n-E%5E%7B(0)%7D_m)%5Cbraket%7Bm%5E%7B0%7D%7Cn%5E%7B(1)%7D%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbraket%7Bm%5E%7B0%7D%7Cn%5E%7B(1)%7D%7D=%5Cfrac%7B%5Cbra%7Bm%5E%7B0%7D%7DV%5Cket%7Bn%5E%7B(0)%7D%7D%7D%7B(E%5E%7B(0)%7D_n-E%5E%7B(0)%7D_m)%7D%0A"></p>
<p>With some arguments, if we impose that <img src="https://latex.codecogs.com/png.latex?%5Cbraket%7Bn%5E%7B(0)%7D%7Cn%7D=1">, then <img src="https://latex.codecogs.com/png.latex?%5Cbraket%7Bn%5E%7B(0)%7D%7Cn%5E%7B(1)%7D%7D=0"> and we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cboxed%7B%5Cket%7Bn%5E%7B(1)%7D%7D%20=%20%5Csum_%7Bm%20%5Cneq%20n%7D%20%5Cfrac%7B%5Cbra%7Bm%5E%7B(0)%7D%7D%20V%20%5Cket%7Bn%5E%7B(0)%7D%7D%7D%7BE_n%5E%7B(0)%7D%20-%20E_m%5E%7B(0)%7D%7D%20%5Cket%7Bm%5E%7B(0)%7D%7D%7D%0A"></p>



 ]]></description>
  <category>quantum mechanics</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post7/</guid>
  <pubDate>Wed, 14 Jan 2026 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Derivation of the Klein Gordon Equation</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post6/</link>
  <description><![CDATA[ 





<p>In classical mechanics, the total energy of a system can be written as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE%20=%20T%20+%20V%20=%20%5Cfrac%7B1%7D%7B2%7D%20mv%5E2%20+%20V%20=%20%5Cfrac%7Bp%5E2%7D%7B2m%7D%20+%20V%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?T"> and <img src="https://latex.codecogs.com/png.latex?V"> are the kinetic and potential energy of a system, respectively. In quantum mechanics, we promote these classical variables to Hermitian operators, where we use the standard substitutions in the position basis are</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BE%7D%20=%20i%20%5Chbar%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20t%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bp%7D%20=%20-%20i%20%5Chbar%20%5Cnabla%0A"></p>
<p>and the energy relation becomes</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ai%20%5Chbar%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20t%7D%20=%20-%5Cfrac%7B%5Chbar%5E2%7D%7B2m%7D%5Cnabla%5E2+V%0A"></p>
<p>and multiplication of the wavefunction <img src="https://latex.codecogs.com/png.latex?%5Cpsi"> yields</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ai%20%5Chbar%20%5Cfrac%7B%5Cpartial%20%5Cpsi%7D%7B%5Cpartial%20t%7D%20=%20(-%5Cfrac%7B%5Chbar%5E2%7D%7B2m%7D%5Cnabla%5E2+V)%20%5Cpsi%0A"></p>
<p>the Schrodinger Equation. For the free particle, we can forget about <img src="https://latex.codecogs.com/png.latex?V"> and the relation reduces to</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ai%20%5Chbar%20%5Cfrac%7B%5Cpartial%20%5Cpsi%7D%7B%5Cpartial%20t%7D%20=%20-%5Cfrac%7B%5Chbar%5E2%7D%7B2m%7D%5Cnabla%5E2%20%5Cpsi%0A"></p>
<p>We derived this from a non-relativistic nergy relation. To introduce relativity into our theory, we can instead start from the relativistic energy relation for a free particle</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE%5E2%20=%20p%5E2c%5E2%20+%20m%5E2c%5E4%0A"></p>
<p>and plug in our operators as before</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A-%20%5Chbar%5E2%20%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%20t%5E2%7D%20=%20-%5Chbar%5E2%20%5Cnabla%5E2%20c%5E2%20+%20m%5E2%20c%5E4%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A-%20%5Chbar%5E2%20%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%20t%5E2%7D%5Cpsi%20=%20(-%5Chbar%5E2%20%5Cnabla%5E2%20c%5E2%20+%20m%5E2%20c%5E4)%20%5Cpsi%0A"></p>
<p>Rearranging yields</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Chbar%5E2%20%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%20t%5E2%7D-%5Chbar%5E2%20%5Cnabla%5E2%20c%5E2%20+%20m%5E2%20c%5E4)%20%5Cpsi%20=%200%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cfrac%7B1%7D%7Bc%5E2%7D%20%5Cfrac%7B%5Cpartial%5E2%7D%7B%5Cpartial%20t%5E2%7D-%20%5Cnabla%5E2%20+%20%5Cfrac%7Bm%5E2%20c%5E2%7D%7B%5Chbar%5E2%7D)%20%5Cpsi%20=%200%0A"></p>
<p>This is known a the Klein-Gordon equation. Historically, other physicists at the time were pretty well satisfied with this equation as a relativistic version of the Schrodinger Equation. However, a clever man by the name of Paul Dirac thought that there were problems with this equation. Firstly, it was second order in time, which means that you’d need to know the initial state <img src="https://latex.codecogs.com/png.latex?%5Cpsi(0)"> and it’s first derivative <img src="https://latex.codecogs.com/png.latex?%5Cpsi'(0)"> in order to evolve it in time. Secondly, for reasons that I won’t get into here, being second order in time means that interpreting the probability of the Klein Gordon equation allows negative probability, which is nonsensical.</p>



 ]]></description>
  <category>quantum mechanics</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post6/</guid>
  <pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The Distribution Shift Problem in LLMs</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post5/</link>
  <description><![CDATA[ 





<p>In preparation for graduate school and future research, I have decided to learn more about statistical learning theory, which is an area of machine learning that I haven’t really looked at up until now. An interesting case study is the problem of LLM hallucination, which is a problem that any person who has spent a sufficient amount of time around chatbots has probably encountered.</p>
<p>An LLM is self-supervised learning mechanism, where a model learns to predict the next token given a sequence of previous tokens. The sentence “The current president is Donald” should be met with an output token of “Trump”. In reality, these tokens usually aren’t words, but character bits (ie. ‘ae’, ‘ee’, ‘e’, etc.) and the bits to use in the dictionary is decided by information theory.</p>
<p>Let</p>
<p><img src="https://latex.codecogs.com/png.latex?X"> be the space of possible token sequences</p>
<p><img src="https://latex.codecogs.com/png.latex?Y"> be the space of possible next tokens</p>
<p><img src="https://latex.codecogs.com/png.latex?P_%7B%5Ctext%7Btrain%7D%7D(x,y)"> be the training distribution</p>
<p><img src="https://latex.codecogs.com/png.latex?P_%7B%5Ctheta%7D(y%20%7C%20x)"> be the conditional distribution over the next token sequences given a sequence</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(%5Ctheta)%20=%20%5Cmathbb%7BE%7D_%7B(x,y)%20%5Csim%20P_%7Btrain%7D(x,y)%7D%5B-%5Clog%20P_%7B%5Ctheta%7D(y%20%5Cmid%20x)%5D"></p>
<p>In machine learning, the model minimizes <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D"> over time. The so called “out of distribution” problem happens upon deployment, when</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7B%5Ctext%7Btrain%7D%7D(x,y)%20%5Cneq%20P_%7B%5Ctext%7Btest%7D%7D(x,y)%0A"></p>
<p>which yields hallucination and inability to derive new science. This is in contrast the assumption that underlies most theoretical and experimental machine learning that the testing and training distribution are the same. A measure for this distribution difference can be given by the Kullback-Leibler divergence</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD_%7B%5Cmathrm%7BKL%7D%7D(P_%7B%5Ctext%7Btrain%7D%7D%20%5C,%5C%7C%5C,%20P_%7B%5Ctext%7Btest%7D%7D)%0A"></p>



 ]]></description>
  <category>artificial intelligence</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post5/</guid>
  <pubDate>Fri, 28 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The completeness relation in quantum mechanics</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post4/</link>
  <description><![CDATA[ 





<p>A very simple but useful relation in quantum mechanics is the so called completeness relation. Here, I will derive it</p>
<p>For any <img src="https://latex.codecogs.com/png.latex?%5Cket%7B%5Cpsi%7D"> living in a Hilbert space, you can represent the vector as a linear combination of some orthonormal bases</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cket%7B%5Cpsi%7D%20=%20%5Csum_%7Bi%7D%20c_%7B%5Calpha_i%7D%20%5Cket%7B%5Calpha_i%7D%0A"></p>
<p>For any one of these orthonormal bases, applying the bra <img src="https://latex.codecogs.com/png.latex?%5Cbra%7B%5Calpha_k%7D"> with the orthonormality condition <img src="https://latex.codecogs.com/png.latex?%5Cbraket%7B%5Calpha_i%20%7C%20%5Calpha_j%7D%20=%20%5Cdelta_%7Bij%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbraket%7B%5Calpha_k%20%7C%20%5Cpsi%7D%20=%20%5Cbra%7B%5Calpha_k%7D%20(%5Csum_%7Bi%7D%20c_%7B%5Calpha_i%7D%20%5Cket%7B%5Calpha_i%7D)%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbraket%7B%5Calpha_k%20%7C%20%5Cpsi%7D%20=%20c_%7B%5Calpha_k%7D%0A"></p>
<p>So we can rewrite this</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cket%7B%5Cpsi%7D%20=%20%5Csum_%7Bi%7D%20c_%7B%5Calpha_i%7D%20%5Cket%7B%5Calpha_i%7D%0A"></p>
<p>as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cket%7B%5Cpsi%7D%20=%20%5Csum_%7Bi%7D%20%5Cket%7B%5Calpha_i%7D%20%5Cbraket%7B%5Calpha_i%20%7C%20%5Cpsi%7D%0A"></p>
<p>Since <img src="https://latex.codecogs.com/png.latex?%5Cket%7B%5Cpsi%7D"> is arbitrary, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BI%7D%20=%20%5Csum_%7Bi%7D%20%5Cket%7B%5Calpha_i%7D%20%5Cbra%7B%5Calpha_i%7D%0A"></p>
<p>The completeness relation. For the continuous case, you have the integral</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BI%7D%20=%20%5Cint%20da%20%5Cket%7Ba%7D%20%5Cbra%7Ba%7D%0A"></p>



 ]]></description>
  <category>quantum mechanics</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post4/</guid>
  <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The Differences Between the Computer and the Brain</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post2/</link>
  <description><![CDATA[ 





<p>I’ve recently just finished reading the book “The Computer and The Brain” by John Von Neumann. A brilliant physicist, he contributed a great many things to quantum mechanics, mathematics, economics, and computer science. The book that he wrote was his opinions and observations on the differences between hardware of the digital computers that had at the time, only recently began being developed and the biological “wetware” that is the brain. Interestingly, this book was a collection of his notes that he was working on just before he died. It may very well be the case that he could have had alot more to say.</p>
<p>Here I’m going to talk about some major points that I thought were interesting in the book, as well as a comparison between how the technology looked back then and the developments that have been made since.</p>
<ul>
<li>Error Resilience as a Trade off of Precision</li>
</ul>
<p>In the book, von Neumann highlights an interesting thought: that error resilience is a trade off of precision. To elaborate on this, one could consider a digital machine. In any such machine, the execution of said machine depends on the information stored in memory and the specific sequence of instructions that the computer executes. It’s imperative that these digits are to be represented exactly as the programmer intends. In the case that one is flipped (say from a cosmic particle or something) could change the value of a store number entirely or possibly even crash a program. The brain, on the other hand, is not as vulnerable to tiny perturbations. A spike recieved at time <img src="https://latex.codecogs.com/png.latex?t"> will not differ in a very meaningful way if that spike were offset to time <img src="https://latex.codecogs.com/png.latex?t+%5CDelta%20t"> for some small <img src="https://latex.codecogs.com/png.latex?%5CDelta%20t">. It should be noted that this noise tolerance comes at a tradeoff of precision.</p>
<p>To consider what exactly we mean by precision, we can consider the quantity of jitter. Suppose we have a spike train denoted by the times <img src="https://latex.codecogs.com/png.latex?%5C%7B%20t_0,%20t_1,%20%5Cdots,%20t_k%5C%7D">. We can take the interspike intervals and group them into another list <img src="https://latex.codecogs.com/png.latex?%5C%7Bi_0,%20i_1,%20%5Cdots,%20i_%7Bk-1%7D%5C%7D">. Taking the standard deviation of this list we have jitter. We can use this as a measure of timing precision in a neuron. In contrast, a clock edge in a digital computer must have a jitter of <img src="https://latex.codecogs.com/png.latex?10%5E%7B-12%7D"> seconds, otherwise the effects cascade downards and calculations get messed up. Comparing this with the precision of a neuron, is a difference in 9 orders of magnitude. Clearly, the neuron’s timing fidelity is much less sensitive than a digital computer is required to be.</p>
<ul>
<li>Serial versus Parallel Organization and Architecture Differences</li>
</ul>
<p>Digital programs (typically) execute programs sequentially, reflecting its serial nature. Brains on the other hand operate in millisecond level precisions as we have established. Despite this seemingly superior advantage of digital computers, parallelism is what makes the brain able to create rich, semantic representations. Control is decentralized, and computation arises from large networks of activity rather than symbolic manipulation.</p>
<p>The von Neumann machine has separated memory and computation units, whereas the brain has them encoded into the same fundamental unit. Synapses store long term data, neurons both compute and store nonlinearities.</p>
<ul>
<li>Different Notational Systems and Short Codes</li>
</ul>
<p>Neumann estimated t</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A"></p>



 ]]></description>
  <category>artificial intelligence</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post2/</guid>
  <pubDate>Fri, 21 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The Expectation Value of An Observable in Quantum mechanics</title>
  <link>https://alskaf1293.github.io/my-blog/posts/post3/</link>
  <description><![CDATA[ 





<p>In quantum mechanics, an observable is given by the Hermitian operator <img src="https://latex.codecogs.com/png.latex?%5Chat%7BQ%7D">. The expectation value of said observable is given by</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20Q%20%5Crangle%20=%20%5Cbra%7B%5Cpsi%7D%20%5Chat%7BQ%7D%20%5Cket%7B%5Cpsi%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cket%7B%5Cpsi%7D"> can be expanded in the basis of the observable, given with the coefficients</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cket%7B%5Cpsi%7D%20=%20c_1%5Cket%7Bq_1%7D%20+%20c_2%5Cket%7Bq_2%7D%20+%20%5Cdots%20+%20c_k%20%5Cket%7Bq_k%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BQ%7D%5Cket%7B%5Cpsi%7D%20=%20%5Chat%7BQ%7D(c_1%5Cket%7Bq_1%7D%20+%20c_2%5Cket%7Bq_2%7D%20+%20%5Cdots%20+%20c_k%20%5Cket%7Bq_k%7D)%0A"> and given with the observable relation <img src="https://latex.codecogs.com/png.latex?%5Chat%7BQ%7D%5Cket%7Bq_j%7D%20=%20q_j%5Cket%7Bq_j%7D">, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbra%7B%5Cpsi%7D%20%5Chat%7BQ%7D%20%5Cket%7B%5Cpsi%7D%20=%20(c%5E*_1%5Cbra%7Bq_1%7D%20+%20c%5E*_2%5Cbra%7Bq_2%7D%20+%20%5Cdots%20+%20c%5E*_k%20%5Cbra%7Bq_k%7D)%20%5Cleft(c_1%20q_1%5Cket%7Bq_1%7D%20+%20c_2%20q_2%5Cket%7Bq_2%7D%20+%20%5Cdots%20+%20c_k%20q_k%5Cket%7Bq_k%7D%20%5Cright)%20%5C%5C%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20Q%20%5Crangle%20=%20%5Csum_%7Bi,j%7D%20c%5E*_i%20c_j%20q_j%20%5Cbraket%7Bq_i%7Cq_j%7D%0A"></p>
<p>and using the orthonormality condition <img src="https://latex.codecogs.com/png.latex?%5Cbraket%7Bq_i%7Cq_j%7D%20=%20%5Cdelta_%7Bij%7D">, we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20Q%20%5Crangle%20=%20%5Csum_%7Bj%7D%20%7Cc_j%7C%5E2%20q_j%0A"></p>
<p>This corresponds exactly to the expectation value equation.</p>



 ]]></description>
  <category>quantum mechanics</category>
  <guid>https://alskaf1293.github.io/my-blog/posts/post3/</guid>
  <pubDate>Fri, 21 Nov 2025 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
